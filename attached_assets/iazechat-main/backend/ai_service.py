"""
Servi√ßo de IA para responder mensagens automaticamente
Suporta OpenAI, Anthropic Claude e Google Gemini via Emergent LLM Key
"""
import os
from typing import List, Dict, Optional
from emergentintegrations.llm.chat import LlmChat, UserMessage
import logging
from datetime import datetime

# Configurar logger espec√≠fico para IA com arquivo dedicado
logger = logging.getLogger("ai_agent")
logger.setLevel(logging.INFO)

# Handler para arquivo
file_handler = logging.FileHandler("/var/log/ai_agent.log")
file_handler.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s [%(levelname)s] %(message)s', datefmt='%Y-%m-%d %H:%M:%S')
file_handler.setFormatter(formatter)
logger.addHandler(file_handler)

# Handler para console
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_handler.setFormatter(formatter)
logger.addHandler(console_handler)

class AIAgentService:
    """Servi√ßo para gerenciar respostas de IA"""
    
    def __init__(self):
        self.api_key = os.getenv('EMERGENT_LLM_KEY', '')
    
    async def generate_response(
        self,
        agent_config: Dict,
        message: str,
        conversation_history: List[Dict] = None,
        client_data: Dict = None
    ) -> Optional[str]:
        """
        Gera resposta da IA baseada nas configura√ß√µes do agente
        
        Args:
            agent_config: Configura√ß√£o do agente IA (instru√ß√µes, modelo, etc)
            message: Mensagem do cliente
            conversation_history: Hist√≥rico de mensagens (opcional)
            client_data: Dados do cliente (credenciais se permitido)
        
        Returns:
            Resposta da IA ou None se houver erro
        """
        logger.info("="*80)
        logger.info(f"ü§ñ INICIANDO GERA√á√ÉO DE RESPOSTA DA IA")
        logger.info(f"üìù Mensagem recebida: {message[:100]}...")
        logger.info(f"üë§ Agente IA: {agent_config.get('name', 'Sem nome')} (ID: {agent_config.get('id', 'N/A')})")
        
        try:
            # Usar API key do agente ou fallback para Emergent key
            api_key = agent_config.get('api_key', self.api_key)
            if not api_key:
                logger.error("üí• ERRO CR√çTICO: Nenhuma API key configurada para IA")
                return None
            
            logger.info(f"üîë API Key presente: {api_key[:10]}...{api_key[-4:] if len(api_key) > 14 else ''}")
            
            # Construir system message com todas as instru√ß√µes
            system_message = self._build_system_prompt(agent_config, client_data)
            logger.info(f"üìã System Prompt constru√≠do ({len(system_message)} caracteres)")
            logger.info(f"üìã System Prompt preview: {system_message[:200]}...")
            
            # Configurar chat
            provider = agent_config.get('llm_provider', 'openai')
            model = agent_config.get('llm_model', 'gpt-4o-mini')
            
            logger.info(f"üîß Configura√ß√£o LLM:")
            logger.info(f"   - Provider: {provider}")
            logger.info(f"   - Model: {model}")
            logger.info(f"   - Session ID: agent_{agent_config.get('id', 'default')}")
            
            chat = LlmChat(
                api_key=api_key,
                session_id=f"agent_{agent_config.get('id', 'default')}",
                system_message=system_message
            ).with_model(provider, model)
            
            logger.info(f"‚úÖ LlmChat configurado com sucesso")
            
            # Criar mensagem do usu√°rio
            user_message = UserMessage(text=message)
            logger.info(f"üì® Enviando mensagem para LLM...")
            
            # Enviar e obter resposta
            response = await chat.send_message(user_message)
            
            logger.info(f"‚úÖ RESPOSTA RECEBIDA DO LLM!")
            logger.info(f"üì§ Resposta ({len(response)} caracteres): {response[:200]}...")
            logger.info("="*80)
            
            return response
            
        except Exception as e:
            logger.error(f"üí• ERRO CR√çTICO ao gerar resposta da IA:")
            logger.error(f"   Tipo: {type(e).__name__}")
            logger.error(f"   Mensagem: {str(e)}")
            import traceback
            logger.error(f"   Traceback:\n{traceback.format_exc()}")
            logger.info("="*80)
            return None
    
    def _build_system_prompt(self, agent_config: Dict, client_data: Dict = None) -> str:
        """Constr√≥i o prompt do sistema com todas as configura√ß√µes"""
        parts = []
        
        # Quem √© o agente
        if agent_config.get('who_is'):
            parts.append(f"QUEM VOC√ä √â: {agent_config['who_is']}")
        
        # O que faz
        if agent_config.get('what_does'):
            parts.append(f"O QUE VOC√ä FAZ: {agent_config['what_does']}")
        
        # Objetivo
        if agent_config.get('objective'):
            parts.append(f"SEU OBJETIVO: {agent_config['objective']}")
        
        # Como responder
        if agent_config.get('how_respond'):
            parts.append(f"COMO RESPONDER: {agent_config['how_respond']}")
        
        # Instru√ß√µes gerais
        if agent_config.get('instructions'):
            parts.append(f"INSTRU√á√ïES: {agent_config['instructions']}")
        
        # Base de conhecimento
        if agent_config.get('knowledge_base'):
            parts.append(f"BASE DE CONHECIMENTO:\n{agent_config['knowledge_base']}")
        
        # Temas a evitar
        if agent_config.get('avoid_topics'):
            parts.append(f"EVITE FALAR SOBRE: {agent_config['avoid_topics']}")
        
        # Palavras a evitar
        if agent_config.get('avoid_words'):
            parts.append(f"N√ÉO USE ESTAS PALAVRAS: {agent_config['avoid_words']}")
        
        # Links permitidos
        if agent_config.get('allowed_links'):
            parts.append(f"LINKS QUE VOC√ä PODE COMPARTILHAR:\n{agent_config['allowed_links']}")
        
        # Regras customizadas
        if agent_config.get('custom_rules'):
            parts.append(f"REGRAS ESPECIAIS:\n{agent_config['custom_rules']}")
        
        # Credenciais do cliente (se permitido)
        if agent_config.get('can_access_credentials') and client_data:
            if client_data.get('pinned_user') or client_data.get('pinned_pass'):
                parts.append(f"\nCREDENCIAIS DO CLIENTE (use quando necess√°rio):")
                if client_data.get('pinned_user'):
                    parts.append(f"- Usu√°rio: {client_data['pinned_user']}")
                if client_data.get('pinned_pass'):
                    parts.append(f"- Senha: {client_data['pinned_pass']}")
        
        # Restri√ß√£o de conhecimento
        if agent_config.get('knowledge_restriction'):
            parts.append("\n‚ö†Ô∏è IMPORTANTE: Voc√™ s√≥ deve responder com base nas informa√ß√µes fornecidas acima. Se n√£o souber algo, diga que n√£o tem essa informa√ß√£o.")
        
        # Detector de idioma
        if agent_config.get('auto_detect_language'):
            parts.append("\nüåç Detecte o idioma do usu√°rio e responda no mesmo idioma automaticamente.")
        
        # Timezone
        timezone = agent_config.get('timezone', 'America/Sao_Paulo')
        parts.append(f"\nüïê Fuso hor√°rio: {timezone}")
        
        return "\n\n".join(parts)

# Inst√¢ncia global
ai_service = AIAgentService()
